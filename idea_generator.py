"""
Inspiration Bot - AI Idea Generator
Uses Google Gemini API to generate creative project ideas
Auto-detects latest available model
"""
import json
import random
import re
from difflib import SequenceMatcher

from google import genai
from google.genai import types
from loguru import logger

from config import settings
from idea_history import IdeaHistory
from idea_summary_store import IdeaSummaryStore


class IdeaGenerator:
    """
    Gemini AIë¥¼ ì‚¬ìš©í•œ ì°½ì˜ì  í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±
    ìë™ìœ¼ë¡œ ìµœì‹  flash ëª¨ë¸ ê°ì§€
    """
    
    def __init__(self):
        self.client = genai.Client(api_key=settings.gemini_api_key)
        self.model = self._get_best_model()
        self.history = IdeaHistory()
        self.summary_store = IdeaSummaryStore()
        logger.info(f"ğŸ’¡ IdeaGenerator ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model})")
    
    def _get_best_model(self) -> str:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  flash ëª¨ë¸ ìë™ ê°ì§€
        ìš°ì„ ìˆœìœ„: gemini-2.0-flash > gemini-1.5-flash > ê¸°íƒ€ flash
        """
        try:
            models = self.client.models.list()
            model_names = [m.name for m in models]
            
            # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì²´í¬
            priority_models = [
                'gemini-2.0-flash',
                'gemini-1.5-flash', 
                'gemini-1.5-flash-latest',
                'gemini-2.0-flash-lite',
            ]
            
            for preferred in priority_models:
                for name in model_names:
                    clean_name = name.replace('models/', '')
                    if clean_name == preferred:
                        logger.info(f"ğŸ” ìë™ ê°ì§€ëœ ìµœì‹  ëª¨ë¸: {clean_name}")
                        return clean_name
            
            # ìš°ì„ ìˆœìœ„ì— ì—†ìœ¼ë©´ ì•„ë¬´ flash ëª¨ë¸ì´ë‚˜ ì‚¬ìš©
            for name in model_names:
                clean_name = name.replace('models/', '')
                if 'flash' in clean_name.lower() and 'exp' not in clean_name.lower():
                    logger.info(f"ğŸ” ê°ì§€ëœ flash ëª¨ë¸: {clean_name}")
                    return clean_name
            
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ì„¤ì •ëœ ëª¨ë¸ ì‚¬ìš©
        return settings.gemini_model
    
    def get_available_models_info(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            models = self.client.models.list()
            flash_models = []
            for m in models:
                if 'flash' in m.name.lower() or 'pro' in m.name.lower():
                    flash_models.append(m.name)
            return "\n".join(flash_models[:10])  # ìƒìœ„ 10ê°œë§Œ
        except Exception as e:
            return f"ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    async def generate_idea(self, idea_type: str = "mixed") -> str:
        """
        ì°½ì˜ì ì¸ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±
        
        Args:
            idea_type: "mixed" (í•˜ë“œì›¨ì–´+SW) or "software" (í•œêµ­ì¸ í˜ì¸í¬ì¸íŠ¸ SW)

        Returns:
            í¬ë§·íŒ…ëœ ì•„ì´ë””ì–´ ë¬¸ìì—´
        """
        # ìµœê·¼ ì•„ì´ë””ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ë°©ì§€ìš©)
        recent_ideas = self.history.get_recent_titles()
        summary_context = self.summary_store.get_recent_context(limit=80)
        recent_context = ""
        if recent_ideas:
            recent_context = f"\n**ì œì™¸í•  ì´ì „ ì•„ì´ë””ì–´ë“¤ (ì¤‘ë³µ ì ˆëŒ€ ê¸ˆì§€):**\n" + "\n".join([f"- {t}" for t in recent_ideas])
        summary_file_context = ""
        if summary_context:
            summary_file_context = (
                "\n**ê¸°ì¡´ ì•„ì´ë””ì–´ ìš”ì•½ íŒŒì¼ ë‚´ìš© (ìœ ì‚¬/ì¤‘ë³µ ì ˆëŒ€ ê¸ˆì§€):**\n"
                f"{summary_context}\n"
            )
        
        if idea_type == "software":
            # SW ì „ìš© (í•œêµ­ì¸ í˜ì¸í¬ì¸íŠ¸)
            age_groups = ["20ëŒ€", "30ëŒ€"]
            target_age = random.choice(age_groups)
            
            prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì¸ì˜ ì‹¤ì œ ë¶ˆí¸í•¨ì„ í•´ê²°í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ì„œë¹„ìŠ¤ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**íƒ€ê²Ÿ ìœ ì €:** {target_age} í•œêµ­ì¸
{recent_context}
{summary_file_context}

**ëª©í‘œ:**
í•˜ë“œì›¨ì–´ ì—†ì´ ì›¹(Web) ë˜ëŠ” ì•±(App)ë§Œìœ¼ë¡œ 2-3ì¼ ë‚´ í”„ë¡œí† íƒ€ì… êµ¬í˜„ì´ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ë¥¼ ê¸°íší•˜ì„¸ìš”.
ì‹¤ì œ í•œêµ­ ì»¤ë®¤ë‹ˆí‹°(DC, í¨ì½”, ë„¤ì´íŠ¸íŒ, ë§˜ì¹´í˜ ë“±)ì—ì„œ ìì£¼ í˜¸ì†Œí•˜ëŠ” êµ¬ì²´ì ì¸ 'ë¶ˆí¸í•¨(Pain Point)'ì„ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.

**ê·œì¹™:**
1. **100% ì†Œí”„íŠ¸ì›¨ì–´ ì•„ì´ë””ì–´** (í•˜ë“œì›¨ì–´ í•„ìš” ì—†ìŒ)
2. **í•œêµ­ íŠ¹í™”** (í•œêµ­ì˜ ë¬¸í™”, ë²•ê·œ, ìƒí™œ ìŠµê´€ ë°˜ì˜)
3. ìˆ˜ìµí™” ê°€ëŠ¥ì„±ì´ë‚˜ ìœ ì € í™•ë³´ ì „ëµ í¬í•¨
4. ê°œë°œ ë‚œì´ë„: ì£¼ë§ì— í˜¼ìì„œ MVP ê°œë°œ ê°€ëŠ¥ ìˆ˜ì¤€
5. ê¸°ì¡´ ì•„ì´ë””ì–´ ìš”ì•½ íŒŒì¼ê³¼ ì œëª©/í•µì‹¬ í•´ê²° ë°©ì‹ì´ ê²¹ì¹˜ë©´ ì•ˆ ë¨
6. ì´ë¯¸ ë„ë¦¬ ì•Œë ¤ì§„ ê¸°ì¡´ ì„œë¹„ìŠ¤(êµ­ë‚´/í•´ì™¸ ìƒìš© ì„œë¹„ìŠ¤)ë¥¼ ë‹¨ìˆœ ë³µì œí•œ ì•„ì´ë””ì–´ëŠ” ê¸ˆì§€

**ì‘ë‹µ í˜•ì‹:**

ì˜ê°ë´‡ (ì†Œí”„íŠ¸ì›¨ì–´ ver.)
**í”„ë¡œì íŠ¸ ì´ë¦„:** "í”„ë¡œì íŠ¸ëª…" ({target_age} íƒ€ê²Ÿ)

**íƒ€ê²Ÿì˜ ë¶ˆí¸í•¨:**
(êµ¬ì²´ì ì¸ ìƒí™© ë¬˜ì‚¬ì™€ ì‹¤ì œ ê²ªëŠ” ë¬¸ì œì )

**í•´ê²° ì†”ë£¨ì…˜:**
(ì›¹/ì•±ìœ¼ë¡œ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€)

**í•µì‹¬ ê¸°ëŠ¥:**
1. ê¸°ëŠ¥1
2. ê¸°ëŠ¥2

**ê¸°ìˆ  ìŠ¤íƒ:**
- í”„ë¡ íŠ¸ì—”ë“œ/ëª¨ë°”ì¼:
- ë°±ì—”ë“œ/DB:
- ì£¼ìš” API/ë¼ì´ë¸ŒëŸ¬ë¦¬:

**ê¸°ëŒ€ íš¨ê³¼:**
(ì‚¬ìš©ìê°€ ì–»ëŠ” ì´ë“)

---
ìœ„ í˜•ì‹ìœ¼ë¡œ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

        else:
            # ê¸°ì¡´ Mixed (í•˜ë“œì›¨ì–´+SW)
            prompt = f"""ë‹¹ì‹ ì€ ê°œë°œìë“¤ì—ê²Œ ì˜ê°ì„ ì£¼ëŠ” ì°½ì˜ì ì¸ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{recent_context}
{summary_file_context}

ì¬ë¯¸ìˆê³  ì‹ ë°•í•œ í† ì´ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ í•˜ë‚˜ ìƒì„±í•´ì£¼ì„¸ìš”. (í•˜ë“œì›¨ì–´, IoT, SW ê²°í•© í™˜ì˜)

**ê·œì¹™:**
1. ì‹¤í˜„ ê°€ëŠ¥í•˜ë©´ì„œë„ ë…íŠ¹í•œ ì•„ì´ë””ì–´
2. IoT, ìë™í™”, AI, ì›¹, ëª¨ë°”ì¼, í•˜ë“œì›¨ì–´ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ ê°€ëŠ¥
3. ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê±°ë‚˜ ì‹¤ìš©ì ì¸ ë™ê¸° í¬í•¨
4. **ì´ì „ì— ì œì•ˆí•œ ê²ƒê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì£¼ì œ**
5. ê¸°ì¡´ ì•„ì´ë””ì–´ ìš”ì•½ íŒŒì¼ê³¼ ê²¹ì¹˜ê±°ë‚˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì´ ìœ ì‚¬í•˜ë©´ ì•ˆ ë¨
6. ì´ë¯¸ ìƒìš©í™”/ëŒ€ì¤‘í™”ëœ ì„œë¹„ìŠ¤ì˜ ë‹¨ìˆœ ëª¨ë°©ì€ ê¸ˆì§€

**ì‘ë‹µ í˜•ì‹:**

ì˜ê°ë´‡ (Maker ver.)
**í”„ë¡œì íŠ¸ ì´ë¦„:** "í”„ë¡œì íŠ¸ëª…"

**í•œ ì¤„ ì„¤ëª…:** ì´ í”„ë¡œì íŠ¸ê°€ ë¬´ì—‡ì¸ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…

**ì™œ ì´ê±¸ ë§Œë“¤ì–´?** ì¬ë¯¸ìˆê±°ë‚˜ ê³µê°ê°€ëŠ” ë™ê¸° ì„¤ëª…

**ì–´ë–»ê²Œ ì‘ë™í•´?** êµ¬ì²´ì ì¸ ì‘ë™ ì›ë¦¬ ì„¤ëª… (2-4ë¬¸ì¥)

**ê¸°ìˆ  ìŠ¤íƒ:**
- ê¸°ìˆ 1 (ìš©ë„)
- ê¸°ìˆ 2 (ìš©ë„)
- ê¸°ìˆ 3 (ìš©ë„)

**ì˜ˆìƒ ê°œë°œ ì‹œê°„:** Nì‹œê°„

---
ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

        return await self._generate_with_novelty_checks(
            base_prompt=prompt,
            idea_type=idea_type,
            summary_context=summary_context,
        )

    def _normalize_text(self, value: str) -> str:
        cleaned = re.sub(r"\s+", "", value.lower())
        return re.sub(r"[^\wê°€-í£]", "", cleaned)

    def _extract_title(self, idea: str) -> str:
        match = re.search(r'\*\*í”„ë¡œì íŠ¸ ì´ë¦„:\*\*\s*"([^"]+)"', idea)
        if match:
            return match.group(1).strip()
        fallback = re.search(r"\*\*í”„ë¡œì íŠ¸ ì´ë¦„:\*\*\s*(.+)", idea)
        if fallback:
            return fallback.group(1).strip().strip('"')
        return ""

    def _extract_short_summary(self, idea: str) -> str:
        one_line = re.search(r"\*\*í•œ ì¤„ ì„¤ëª…:\*\*\s*(.+)", idea)
        if one_line:
            return one_line.group(1).strip()[:180]

        solution = re.search(
            r"\*\*í•´ê²° ì†”ë£¨ì…˜:\*\*\s*(.+?)(?:\n\s*\n|\n\*\*)",
            idea,
            flags=re.DOTALL,
        )
        if solution:
            text = " ".join(solution.group(1).split())
            return text[:180]

        lines = [ln.strip() for ln in idea.splitlines() if ln.strip()]
        if len(lines) > 3:
            return lines[3][:180]
        return idea[:180]

    def _is_too_similar(self, title: str, candidates: list[str]) -> bool:
        norm_title = self._normalize_text(title)
        if not norm_title:
            return False

        for existing in candidates:
            norm_existing = self._normalize_text(existing)
            if not norm_existing:
                continue
            if norm_title == norm_existing:
                return True
            ratio = SequenceMatcher(None, norm_title, norm_existing).ratio()
            if ratio >= 0.82:
                return True
        return False

    def _extract_json_object(self, text: str) -> dict:
        content = text.strip()
        block = re.search(r"\{.*\}", content, flags=re.DOTALL)
        if block:
            content = block.group(0)
        return json.loads(content)

    def _validate_novelty_with_search(
        self,
        idea: str,
        title: str,
        summary_context: str,
    ) -> dict:
        """
        Gemini ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì¤‘ë³µ/ê¸°ì¡´ ì„œë¹„ìŠ¤ ì—¬ë¶€ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
        """
        validate_prompt = f"""ì•„ë˜ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ê°€ 'ìƒˆë¡œìš´ ì•„ì´ë””ì–´'ì¸ì§€ ì—„ê²©íˆ ì‹¬ì‚¬í•˜ì„¸ìš”.

ê²€ì‚¬ ê¸°ì¤€:
1) ê¸°ì¡´ ì•„ì´ë””ì–´ ìš”ì•½ ëª©ë¡ê³¼ ì œëª©/í•µì‹¬ í•´ê²° ë°©ì‹ì´ ìœ ì‚¬í•˜ë©´ íƒˆë½
2) ì´ë¯¸ êµ­ë‚´ì™¸ì—ì„œ ë„ë¦¬ ì„œë¹„ìŠ¤ ì¤‘ì¸ ì œí’ˆ/ì•±/ì›¹ê³¼ ë³¸ì§ˆì ìœ¼ë¡œ ê°™ìœ¼ë©´ íƒˆë½
3) ë‹¨ìˆœí•œ UI/ê¸°ëŠ¥ ì´ë¦„ ë°”ê¾¸ê¸° ìˆ˜ì¤€ë„ íƒˆë½

ê¸°ì¡´ ì•„ì´ë””ì–´ ìš”ì•½ ëª©ë¡:
{summary_context if summary_context else "(ë¹„ì–´ ìˆìŒ)"}

ê²€ì‚¬ ëŒ€ìƒ ì œëª©:
{title}

ê²€ì‚¬ ëŒ€ìƒ ìƒì„¸:
{idea}

ë°˜ë“œì‹œ ì•„ë˜ JSON í•œ ì¤„ë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{"is_novel": true/false, "reason": "íŒì • ì´ìœ ", "similar_examples": ["ìœ ì‚¬ ì„œë¹„ìŠ¤1", "ìœ ì‚¬ ì„œë¹„ìŠ¤2"]}}"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=validate_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    tools=[
                        types.Tool(
                            google_search=types.GoogleSearch()
                        )
                    ],
                ),
            )
            parsed = self._extract_json_object(response.text or "")
            is_novel = bool(parsed.get("is_novel", False))
            reason = str(parsed.get("reason", "")).strip()
            examples = parsed.get("similar_examples", [])
            if not isinstance(examples, list):
                examples = []
            return {
                "is_novel": is_novel,
                "reason": reason or "ê²€ì¦ ê²°ê³¼ ì‚¬ìœ  ë¯¸ì œê³µ",
                "similar_examples": [str(x) for x in examples][:5],
            }
        except Exception as e:
            # ê²€ìƒ‰ ê²€ì¦ ì‹¤íŒ¨ ì‹œ, ë°œì†¡ ì¤‘ë‹¨ë³´ë‹¤ëŠ” ìƒì„± íë¦„ ìœ ì§€
            logger.warning(f"ê²€ìƒ‰ ê¸°ë°˜ ì‹ ê·œì„± ê²€ì¦ ì‹¤íŒ¨(í´ë°±): {e}")
            return {
                "is_novel": True,
                "reason": "ê²€ìƒ‰ ê²€ì¦ ì‹¤íŒ¨ë¡œ í´ë°± í—ˆìš©",
                "similar_examples": [],
            }

    async def _generate_with_novelty_checks(
        self,
        base_prompt: str,
        idea_type: str,
        summary_context: str,
        max_attempts: int = 4,
    ) -> str:
        rejected_reasons: list[str] = []

        try:
            for attempt in range(1, max_attempts + 1):
                retry_context = ""
                if rejected_reasons:
                    retry_context = (
                        "\n\n**ì´ì „ ì‹œë„ íƒˆë½ ì‚¬ìœ  (ë°˜ë“œì‹œ íšŒí”¼):**\n"
                        + "\n".join([f"- {r}" for r in rejected_reasons[-5:]])
                    )

                response = self.client.models.generate_content(
                    model=self.model,
                    contents=base_prompt + retry_context,
                    config=types.GenerateContentConfig(temperature=0.9),
                )
                idea = (response.text or "").strip()
                title = self._extract_title(idea)

                if not title:
                    rejected_reasons.append("í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ ì‹¤íŒ¨")
                    logger.warning(f"ì•„ì´ë””ì–´ ì¬ì‹œë„ {attempt}/{max_attempts}: ì œëª© ì¶”ì¶œ ì‹¤íŒ¨")
                    continue

                # 1ì°¨: ë¡œì»¬ ìœ ì‚¬ë„ ê²€ì‚¬
                history_titles = self.history.get_recent_titles(limit=120)
                summary_titles = self.summary_store.get_all_titles()
                title_pool = list(set(history_titles + summary_titles))
                if self._is_too_similar(title, title_pool):
                    rejected_reasons.append(f"ê¸°ì¡´ ì•„ì´ë””ì–´ì™€ ì œëª© ìœ ì‚¬: {title}")
                    logger.warning(f"ì•„ì´ë””ì–´ ì¬ì‹œë„ {attempt}/{max_attempts}: ì œëª© ìœ ì‚¬ë„ íƒˆë½")
                    continue

                # 2ì°¨: ê²€ìƒ‰ ê¸°ë°˜ ì‹ ê·œì„± ê²€ì‚¬
                novelty = self._validate_novelty_with_search(
                    idea=idea,
                    title=title,
                    summary_context=summary_context,
                )
                if not novelty["is_novel"]:
                    examples = ", ".join(novelty["similar_examples"]) if novelty["similar_examples"] else "ì—†ìŒ"
                    reason = f"{novelty['reason']} (ìœ ì‚¬ ì˜ˆì‹œ: {examples})"
                    rejected_reasons.append(reason)
                    logger.warning(f"ì•„ì´ë””ì–´ ì¬ì‹œë„ {attempt}/{max_attempts}: ê²€ìƒ‰ ê²€ì¦ íƒˆë½ - {reason}")
                    continue

                # í†µê³¼: íˆìŠ¤í† ë¦¬ + ìš”ì•½ íŒŒì¼ ì €ì¥
                self.history.record_idea(title, idea_type)
                summary = self._extract_short_summary(idea)
                self.summary_store.append_summary(title, idea_type, summary)
                logger.success(f"ğŸ’¡ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ìƒì„± ì™„ë£Œ ({idea_type})")
                return idea

            return (
                "âš ï¸ ì˜¤ëŠ˜ì€ ê¸°ì¡´ ì•„ì´ë””ì–´ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒˆ ì•„ì´ë””ì–´ë¥¼ í™•ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
                "ë‚´ì¼ ë‹¤ì‹œ ë” ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ íƒìƒ‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
            )

        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ì•„ì´ë””ì–´ ìƒì„± ì‹¤íŒ¨: {error_msg}")

            if "404" in error_msg or "not found" in error_msg.lower():
                best_model = self._get_best_model()
                return (
                    f"âš ï¸ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤!\n\n"
                    f"ì—ëŸ¬: 404 NOT_FOUND\n"
                    f"í˜„ì¬ ëª¨ë¸ '{self.model}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                    f"ğŸ”„ ìµœì‹  ëª¨ë¸ '{best_model}'(ìœ¼)ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”!\n\n"
                    f"ğŸ“ .env íŒŒì¼ ìˆ˜ì • í•„ìš”:\n"
                    f"GEMINI_MODEL={best_model}"
                )

            return f"âš ï¸ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# Test
async def test_generator():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    generator = IdeaGenerator()
    idea = await generator.generate_idea()
    print(idea)


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_generator())
